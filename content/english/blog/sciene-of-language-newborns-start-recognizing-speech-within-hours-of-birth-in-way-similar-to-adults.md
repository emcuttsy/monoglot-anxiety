+++
author = "Elise Cutts"
categories = ["Science of Language"]
date = ""
description = ""
draft = true
enableComments = true
images = []
sidebar = "right"
subtitle = "A new study found that newborns start recognizing vowel sounds just hours after birth using a speech-processing system very similar to the one adults use to learn and use language"
summary = ""
tags = []
title = "Science of Language: Newborns learn speech sounds using same brain regions as adults"
type = "featured"

+++
< Funny lede >

Researchers from Shenzhen University in China  <nut>

Babies start life already tuned-in to human speech. Newborns respond differently to human speech than to other noises, and they can distinguish their mom's voice from other female voices.

It's also clear that babies start the more sophisticated task of distinguishing different phonemes — the individual sounds that make up human speech — very early, within the first few hours or days of life. But it's still not settled whether phoneme recognition is something we're born with or something that we start learning shortly after birth.

The evidence isn't clear one way or the other. Hearing organs come online at around 24 weeks of gestation, and there is some interesting work showing that newborns come into the world already preferring the sounds of their native language over foreign ones. This would suggest that the infant brain comes pre-installed with phoneme recognition. However, another study found that while newborns can distinguish between simple vowels right after birth, they only start picking up the differences between trickier sounds after training.

# Watching newborn brains learn language

Innate or learned, phoneme recognition clearly starts early. But exactly _how_ that recognition plays out in the infant brain wasn't clear — do newborns have a unique way of processing speech, or do their brains already respond to human language the way adult brains do?

To find out, researchers measured the brain activity of infants to see if — and how — they could distinguish between natural vowel sounds in their native language, Mandarin, and the same vowels played backwards.

{{<notice note "Nerd Alert: How measuring brain activity works">}}

The researchers in this study used a very cool method called Functional Near-Infrared Spectroscopy (fNIRS) to track brain activity, and the nerd in me just couldn't resist giving a quick explanation. Skip this if you don't care.

In a nutshell, fNIRS works by shining light into the brain and seeing how much comes back. In this study, each baby was fit with a cap containing a network of tiny light sensors called optodes, each of which is either red or blue. The red optodes shine near-infrared light into the scalp, which passes harmlessly through human tissue until it bounces back out. The blue optodes measure how much light makes it out of the brain. 

Because active brain areas need more oxygen and because fresh, oxygen-loaded blood absorbs lots of near-infrared light, scientists can measure brain activity by watching how much light from the red optodes makes it to the blue ones.

Cool, right?

{{</ notice  >}}

The researchers "trained" 25 babies to recognize a set of 3 vowels (/ɑː/, /ɔː/ and /iː/) by having them listen to 10-minute recordings of the same vowel sound played forward and then backwards for 5 hours. After training, the babies took a "test" — the scientists played recordings of the vowels they had "learned" both forwards and backwards and watched how their brain activity responded. 2 hours after the 1st test, the babies took the same test again.

For reference, the researchers also gave the same two tests to 25 babies that had "trained" on a different set of vowels () or not trained at all. 

 